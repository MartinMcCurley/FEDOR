#!/usr/bin/env python3
"""
GPU Test Script - Verify RTX 4070 Ti is working properly
"""

print("ğŸ” Testing GPU Setup for RTX 4070 Ti")
print("=" * 50)

# Test PyTorch CUDA
print("\nğŸ”¥ PyTorch CUDA Test:")
try:
    import torch
    if torch.cuda.is_available():
        print(f"âœ… PyTorch CUDA Available: {torch.cuda.is_available()}")
        print(f"âœ… GPU Count: {torch.cuda.device_count()}")
        print(f"âœ… GPU Name: {torch.cuda.get_device_name(0)}")
        
        # Test GPU computation
        x = torch.randn(1000, 1000).cuda()
        y = torch.randn(1000, 1000).cuda()
        z = torch.matmul(x, y)
        print(f"âœ… GPU Computation Test: Matrix multiplication successful")
        print(f"âœ… Result tensor device: {z.device}")
    else:
        print("âŒ PyTorch CUDA not available")
except Exception as e:
    print(f"âŒ PyTorch error: {e}")

# Test CuPy
print("\nğŸš€ CuPy Test:")
try:
    import cupy as cp
    print(f"âœ… CuPy GPU Count: {cp.cuda.runtime.getDeviceCount()}")
    print(f"âœ… GPU Name: {cp.cuda.Device(0).name}")
    print(f"âœ… GPU Memory: {cp.cuda.Device(0).total_memory / (1024**3):.1f} GB")
    
    # Test CuPy computation
    x_cp = cp.random.randn(1000, 1000)
    y_cp = cp.random.randn(1000, 1000)
    z_cp = cp.matmul(x_cp, y_cp)
    print(f"âœ… CuPy Computation Test: Matrix multiplication successful")
    print(f"âœ… Result array device: GPU")
    
    # Memory check
    mempool = cp.get_default_memory_pool()
    gpu_memory_used = mempool.used_bytes() / (1024**3)
    print(f"âœ… GPU Memory Used: {gpu_memory_used:.2f} GB")
    
except Exception as e:
    print(f"âŒ CuPy error: {e}")

print("\nğŸ‰ GPU Setup Verification Complete!")
print("Your RTX 4070 Ti is ready for poker AI training!") 